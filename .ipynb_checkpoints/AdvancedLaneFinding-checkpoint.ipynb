{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## Compute the camera calibration given a set of chessboard images\n",
    "\n",
    "\n",
    "\n",
    "### Identify Chessboard Corners "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mpimage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-297f141be52c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Step through the list and search for chessboard corners\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mpimage' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "image_shape = (1280, 720)\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = mpimage.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points and image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw the corners for analysis\n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        \n",
    "        # Display the original image and the image with the corners drawn for inspection\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,8))\n",
    "        ax1.imshow(cv2.cvtColor(mpimg.imread(fname), cv2.COLOR_BGR2RGB))\n",
    "        ax1.set_title('Original Chessboard', fontsize=15)\n",
    "        ax2.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax2.set_title('Identified Corners', fontsize=15)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate camera distortion coefficient, and camera matrix and make undistort function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the camera distortion coefficient and camera matrix\n",
    "ret, camera_mtx, dist_coeff, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, image_shape, None, None)\n",
    "\n",
    "# function to undistort an image\n",
    "def undistort(img, view=False, mtx=camera_mtx, dist=dist_coeff):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    if view:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,8))\n",
    "        ax1.imshow(img)\n",
    "        ax1.set_title('Original', fontsize=15)\n",
    "        ax2.imshow(undist)\n",
    "        ax2.set_title('Undistorted', fontsize=15)\n",
    "    return undist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a distortion correction to raw images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "images = glob.glob('./test_images/test*.jpg')\n",
    "for fname in images:\n",
    "    img = mpimg.imread(fname)\n",
    "    undistorted = undistort(img, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "for fname in images:\n",
    "    img = mpimg.imread(fname)\n",
    "    undistorted = undistort(img, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use color transforms, gradients, etc., to create a thresholded binary image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining helpful image transformation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def hls_select(img, thresh=(170, 255)):\n",
    "    # Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    binary_output = np.zeros_like(s_channel)\n",
    "    # Apply a threshold to the S channel\n",
    "    binary_output[(s_channel > thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "    # Return a binary image of threshold result\n",
    "    return binary_output\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    # Take the absolute value of the derivative or gradient\n",
    "    sobel_abs = np.absolute(sobel)\n",
    "    # Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    sobel_scale = np.uint8(255*sobel_abs/np.max(sobel_abs))\n",
    "    # Create a mask of 1's where the scaled gradient magnitude is > thresh_min and < thresh_max\n",
    "    binary_output = np.zeros_like(sobel_scale)\n",
    "    binary_output[(sobel_scale >= thresh[0]) & (sobel_scale <= thresh[1])] = 1\n",
    "    # Return this mask as your binary_output image\n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(image, sobel_kernel=3, mag_thresh=(30, 100)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    # Calculate the magnitude \n",
    "    abs_sobelxy = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    sobel_scale = (255*abs_sobelxy/np.max(abs_sobelxy)).astype(np.uint8) \n",
    "    # Create a binary mask where mag thresholds are met\n",
    "    binary_output = np.zeros_like(sobel_scale)\n",
    "    binary_output[(sobel_scale >= mag_thresh[0]) & (sobel_scale <= mag_thresh[1])] = 1\n",
    "    # Return this mask as your binary_output image\n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(image, sobel_kernel=3, thresh=(0.7, 1.3)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    # Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    direction = np.arctan2(abs_sobely, abs_sobelx);\n",
    "    # Create a binary mask where direction thresholds are met\n",
    "    binary_output = np.zeros_like(direction)\n",
    "    binary_output[(direction >= thresh[0]) & (direction <= thresh[1])] = 1\n",
    "    # Return this mask as your binary_output image\n",
    "    return binary_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining what each transform does to the image with specified paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sobel kernel size\n",
    "ksize = 7 # Choose a larger odd number to smooth gradient measurements\n",
    "\n",
    "images = glob.glob('./test_images/test*.jpg')\n",
    "for fname in images:\n",
    "    img = undistort(mpimg.imread(fname), False)\n",
    "    color_converted = hls_select(img)\n",
    "    gradx = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=(40, 200))\n",
    "    grady = abs_sobel_thresh(img, orient='y', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    mag_binary = mag_thresh(img, sobel_kernel=ksize, mag_thresh=(30, 100))\n",
    "    dir_binary = dir_threshold(img, sobel_kernel=ksize, thresh=(0.7, 1.3))    \n",
    "    \n",
    "    f, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(16,8))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original', fontsize=15)\n",
    "    ax2.imshow(color_converted, cmap='gray')\n",
    "    ax2.set_title('s_channel', fontsize=15)\n",
    "    ax3.imshow(gradx, cmap='gray')\n",
    "    ax3.set_title('x gradient', fontsize=15)\n",
    "    ax4.imshow(grady, cmap='gray')\n",
    "    ax4.set_title('y gradient', fontsize=15)\n",
    "    ax5.imshow(mag_binary, cmap='gray')\n",
    "    ax5.set_title('magnitude grad', fontsize=15)\n",
    "    ax6.imshow(dir_binary, cmap='gray')\n",
    "    ax6.set_title('directional grad', fontsize=15)\n",
    "    # Apply each of the thresholding functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### it looks like the s_channel combined with the x gradient image will help us achieve the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('./test_images/test*.jpg')\n",
    "for fname in images:\n",
    "    img = undistort(mpimg.imread(fname), False)\n",
    "    s_channel = hls_select(img)\n",
    "    gradx = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    combined = np.zeros_like(s_channel)\n",
    "    combined[(s_channel > 0) | (gradx > 0)] = 1\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,8))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original', fontsize=15)\n",
    "    ax2.imshow(combined, cmap='gray')\n",
    "    ax2.set_title('s_channel + x_grad', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining a function to change an image to the desired color space and gradient combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_and_gradient(img, view=False):\n",
    "    img = undistort(img, False)\n",
    "    s_channel = hls_select(img)\n",
    "    gradx = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    combined = np.zeros_like(s_channel)\n",
    "    combined[(s_channel > 0) | (gradx > 0)] = 1\n",
    "    if view:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,8))\n",
    "        ax1.imshow(img)\n",
    "        ax1.set_title('Original', fontsize=15)\n",
    "        ax2.imshow(combined, cmap='gray')\n",
    "        ax2.set_title('s_channel + x_grad', fontsize=15)\n",
    "    return combined\n",
    "#     f, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a perspective transform to rectify binary image (\"birds-eye view\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "images = glob.glob('./test_images/straight_lines*.jpg')\n",
    "\n",
    "src = np.float32([[595, 450], [685, 450], [1010, 660], [290, 660]])\n",
    "dst = np.float32([[290, 0], [1010, 0], [1010, 720], [290, 720]], \n",
    "\n",
    "for image in images:\n",
    "    img = undistort(mpimg.imread(image), False)\n",
    "    img_w_init_rect = cv2.polylines(img, src, True, (255, 0, 0), 2)\n",
    "    plt.imshow(img)\n",
    "    plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
